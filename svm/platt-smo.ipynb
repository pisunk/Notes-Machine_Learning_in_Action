{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立一个类存放基本数据以及alphas的缓存\n",
    "class optStruct:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler):  # Initialize the structure with the parameters\n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m, 2)))  # 第一列是有效标志位，第二列是E值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    \"\"\"loadDataSet（对文件进行逐行解析，从而得到每行的类标签和整个数据矩阵）\n",
    "\n",
    "    Args:\n",
    "        fileName 文件名\n",
    "    Returns:\n",
    "        dataMat  数据矩阵\n",
    "        labelMat 类标签\n",
    "    \"\"\"\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the same as simple smo\n",
    "def selectJrand(i, m):\n",
    "    \"\"\"\n",
    "    随机选择一个整数\n",
    "    Args:\n",
    "        i  第一个alpha的下标\n",
    "        m  所有alpha的数目\n",
    "    Returns:\n",
    "        j  返回一个不为i的随机数，在0~m之间的整数值\n",
    "    \"\"\"\n",
    "    j = i\n",
    "    while j == i:\n",
    "        j = int(random.uniform(0, m))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the same as simple smo\n",
    "def clipAlpha(aj, H, L):\n",
    "    \"\"\"clipAlpha(调整aj的值，使aj处于 L<=aj<=H)\n",
    "    Args:\n",
    "        aj  目标值\n",
    "        H   最大值\n",
    "        L   最小值\n",
    "    Returns:\n",
    "        aj  目标值\n",
    "    \"\"\"\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EK计算较多，所以单独拎出来\n",
    "def calcEk(oS, k):\n",
    "    \"\"\"calcEk（求 Ek误差：预测值-真实值的差）\n",
    "\n",
    "    该过程在完整版的SMO算法中陪出现次数较多，因此将其单独作为一个方法\n",
    "    Args:\n",
    "        oS  optStruct对象\n",
    "        k   具体的某一行\n",
    "\n",
    "    Returns:\n",
    "        Ek  预测结果与真实结果比对，计算误差Ek\n",
    "    \"\"\"\n",
    "    fXk = float(multiply(oS.alphas, oS.labelMat).T * (oS.X * oS.X[k, :].T)) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#platt-smo重点\n",
    "#在选择第2个alphas参数时（也就是进行SMO的内循环时），不再是随机选择，而是选择最长步长的那个（就是选择|E_i-Ej|最大的）\n",
    "def selectJ(i, oS, Ei):  # this is the second choice -heurstic, and calcs Ej\n",
    "    \"\"\"selectJ（返回最优的j和Ej）\n",
    "\n",
    "    内循环的启发式方法。\n",
    "    选择第二个(内循环)alpha的alpha值\n",
    "    这里的目标是选择合适的第二个alpha值以保证每次优化中采用最大步长。\n",
    "    该函数的误差与第一个alpha值Ei和下标i有关。\n",
    "    Args:\n",
    "        i   具体的第i一行\n",
    "        oS  optStruct对象\n",
    "        Ei  预测结果与真实结果比对，计算误差Ei\n",
    "\n",
    "    Returns:\n",
    "        j  随机选出的第j一行\n",
    "        Ej 预测结果与真实结果比对\n",
    "        ，计算误差Ej\n",
    "    \"\"\"\n",
    "    maxK = -1\n",
    "    maxDeltaE = 0\n",
    "    Ej = 0\n",
    "    # 首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。\n",
    "    oS.eCache[i] = [1, Ei]\n",
    "\n",
    "    # print 'oS.eCache[%s]=%s' % (i, oS.eCache[i])\n",
    "    # print 'oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T\n",
    "    # \"\"\"\n",
    "    # # 返回非0的：行列值\n",
    "    # nonzero(oS.eCache[:, 0].A)= (\n",
    "    #     行： array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]), \n",
    "    #     列： array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])\n",
    "    # )\n",
    "    # \"\"\"\n",
    "    # print 'nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A)\n",
    "    # # 取行的list\n",
    "    # print 'nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0]\n",
    "    \n",
    "    # 非零E值的行的list列表，所对应的alpha值\n",
    "    validEcacheList = nonzero(oS.eCache[:, 0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:  # 在所有的值上进行循环，并选择其中使得改变最大的那个值\n",
    "            if k == i:\n",
    "                continue  # don't calc for i, waste of time如果j=i直接跳过\n",
    "\n",
    "            # 求 Ek误差：预测值-真实值的差\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k#get max j下标\n",
    "                maxDeltaE = deltaE#get max j's deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:  # 如果是第一次循环，则随机选择一个alpha值\n",
    "        j = selectJrand(i, oS.m)\n",
    "\n",
    "        # 求 Ek误差：预测值-真实值的差\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#更新错误率Ek\n",
    "def updateEk(oS, k):  # after any alpha has changed update the new value in the cache\n",
    "    \"\"\"updateEk（计算误差值并存入缓存中。）\n",
    "\n",
    "    在对alpha值进行优化之后会用到这个值。\n",
    "    Args:\n",
    "        oS  optStruct对象\n",
    "        k   某一列的行号\n",
    "    \"\"\"\n",
    "\n",
    "    # 求 误差：预测值-真实值的差\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1, Ek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#更新b并且返回两个alpha参数是否改变的情况，内循环\n",
    "def innerL(i, oS):\n",
    "    \"\"\"innerL\n",
    "    内循环代码\n",
    "    Args:\n",
    "        i   具体的某一行\n",
    "        oS  optStruct对象\n",
    "\n",
    "    Returns:\n",
    "        0   找不到最优的值\n",
    "        1   找到了最优的值，并且oS.Cache到缓存中\n",
    "    \"\"\"\n",
    "\n",
    "    # 求 Ek误差：预测值-真实值的差\n",
    "    Ei = calcEk(oS, i)\n",
    "\n",
    "    # 约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值)\n",
    "    # 0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。\n",
    "    # 表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。\n",
    "    '''\n",
    "    # 检验训练样本(xi, yi)是否满足KKT条件\n",
    "    yi*f(i) >= 1 and alpha = 0 (outside the boundary)\n",
    "    yi*f(i) == 1 and 0<alpha< C (on the boundary)\n",
    "    yi*f(i) <= 1 and alpha = C (between the boundary)\n",
    "    '''\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        # 选择最大的误差对应的j进行优化。效果更明显\n",
    "        j, Ej = selectJ(i, oS, Ei)#这里在选择j处进行了优化\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "\n",
    "        # L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H:\n",
    "            print(\"L==H\")\n",
    "            return 0\n",
    "\n",
    "        # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "        # 参考《统计学习方法》李航-P125~P128<序列最小最优化算法>\n",
    "        eta = 2.0 * oS.X[i, :] * oS.X[j, :].T - oS.X[i, :] * oS.X[i, :].T - oS.X[j, :] * oS.X[j, :].T\n",
    "        if eta >= 0:\n",
    "            print(\"eta>=0\")\n",
    "            return 0\n",
    "\n",
    "        # 计算出一个新的alphas[j]值\n",
    "        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta\n",
    "        # 并使用辅助函数，以及L和H对其进行调整\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, j)\n",
    "\n",
    "        # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            print(\"j not moving enough\")\n",
    "            return 0\n",
    "\n",
    "        # 然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反\n",
    "        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, i)\n",
    "\n",
    "        # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "        # w= Σ[1~n] ai*yi*xi => b = yj Σ[1~n] ai*yi(xi*xj)\n",
    "        # 所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1)\n",
    "        # 为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i, :] * oS.X[i, :].T - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.X[i, :] * oS.X[j, :].T\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i, :] * oS.X[j, :].T - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.X[j, :] * oS.X[j, :].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#完整版SMO算法\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    \"\"\"\n",
    "    完整SMO算法外循环，与smoSimple有些类似，但这里的循环退出条件更多一些\n",
    "    Args:\n",
    "        dataMatIn    数据集\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率\n",
    "        maxIter 退出前最大的循环次数\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个 optStruct 对象\n",
    "    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler)\n",
    "    iter = 0 # 迭代次数的初始化\n",
    "    entireSet = True # 违反 KKT 条件的标志符\n",
    "    alphaPairsChanged = 0 # 迭代中优化的次数\n",
    "\n",
    "    # 循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）\n",
    "    # 循环迭代结束 或者 循环遍历所有alpha后，alphaPairs还是没变化\n",
    "    '''\n",
    "    外层循环首先遍历所有满足0到C范围内的alpha，即在间隔边界上的支持向量点，\n",
    "    检验它们是否满足KKT条件。如果这些样本点都满足KKT条件，那么遍历整个训练集，检验它们是否满足KKT条件。\n",
    "    '''\n",
    "    # 优化的终止条件：在规定迭代次数下，是否遍历了整个样本或 alpha 是否优化\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "\n",
    "        #  当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。\n",
    "        if entireSet:\n",
    "            # 在数据集上遍历所有的alpha\n",
    "            for i in range(oS.m):\n",
    "                # 是否存在alpha对，存在就+1\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        # 对已存在 alpha对，选出非边界的alpha值，进行优化。\n",
    "        else:\n",
    "            # 遍历所有的非边界alpha值，也就是不在边界0或C上的值。\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0] # 遍历所有非边界样本集\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "\n",
    "        # 如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。\n",
    "        if entireSet:\n",
    "            entireSet = False  # toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0):\n",
    "            entireSet = True\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the same as simple smo\n",
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    \"\"\"\n",
    "    基于alpha计算w值\n",
    "    Args:\n",
    "        alphas        拉格朗日乘子\n",
    "        dataArr       feature数据集\n",
    "        classLabels   目标变量数据集\n",
    "\n",
    "    Returns:\n",
    "        wc  回归系数\n",
    "    \"\"\"\n",
    "    X = mat(dataArr)\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(X)\n",
    "    w = zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i] * labelMat[i], X[i, :].T)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotfig_SVM(xArr, yArr, ws, b, alphas):\n",
    "    \"\"\"\n",
    "    参考地址：\n",
    "       http://blog.csdn.net/maoersong/article/details/24315633\n",
    "       http://www.cnblogs.com/JustForCS/p/5283489.html\n",
    "       http://blog.csdn.net/kkxgx/article/details/6951959\n",
    "    \"\"\"\n",
    "\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr)\n",
    "\n",
    "    # b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)\n",
    "    b = array(b)[0]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # 注意flatten的用法\n",
    "    ax.scatter(xMat[:, 0].flatten().A[0], xMat[:, 1].flatten().A[0])\n",
    "\n",
    "    # x最大值，最小值根据原数据集dataArr[:, 0]的大小而定\n",
    "    x = arange(-1.0, 10.0, 0.1)\n",
    "\n",
    "    # 根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值\n",
    "    y = (-b-ws[0, 0]*x)/ws[1, 0]\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    for i in range(shape(yMat[0, :])[1]):\n",
    "        if yMat[0, i] > 0:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'cx')\n",
    "        else:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'kp')\n",
    "\n",
    "    # 找到支持向量，并在图中标红\n",
    "    for i in range(100):\n",
    "        if alphas[i] > 0.0:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'ro')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L==H\n",
      "fullSet, iter: 0 i:0, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 0 i:1, pairs changed 0\n",
      "fullSet, iter: 0 i:2, pairs changed 1\n",
      "L==H\n",
      "fullSet, iter: 0 i:3, pairs changed 1\n",
      "fullSet, iter: 0 i:4, pairs changed 2\n",
      "fullSet, iter: 0 i:5, pairs changed 2\n",
      "fullSet, iter: 0 i:6, pairs changed 2\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:7, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:8, pairs changed 2\n",
      "fullSet, iter: 0 i:9, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:10, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:11, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:12, pairs changed 2\n",
      "fullSet, iter: 0 i:13, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:14, pairs changed 2\n",
      "fullSet, iter: 0 i:15, pairs changed 2\n",
      "fullSet, iter: 0 i:16, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:17, pairs changed 2\n",
      "fullSet, iter: 0 i:18, pairs changed 3\n",
      "fullSet, iter: 0 i:19, pairs changed 3\n",
      "fullSet, iter: 0 i:20, pairs changed 3\n",
      "fullSet, iter: 0 i:21, pairs changed 3\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:22, pairs changed 3\n",
      "L==H\n",
      "fullSet, iter: 0 i:23, pairs changed 3\n",
      "L==H\n",
      "fullSet, iter: 0 i:24, pairs changed 3\n",
      "fullSet, iter: 0 i:25, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:26, pairs changed 4\n",
      "fullSet, iter: 0 i:27, pairs changed 4\n",
      "fullSet, iter: 0 i:28, pairs changed 4\n",
      "L==H\n",
      "fullSet, iter: 0 i:29, pairs changed 4\n",
      "fullSet, iter: 0 i:30, pairs changed 4\n",
      "fullSet, iter: 0 i:31, pairs changed 4\n",
      "fullSet, iter: 0 i:32, pairs changed 4\n",
      "fullSet, iter: 0 i:33, pairs changed 4\n",
      "fullSet, iter: 0 i:34, pairs changed 4\n",
      "fullSet, iter: 0 i:35, pairs changed 4\n",
      "fullSet, iter: 0 i:36, pairs changed 4\n",
      "fullSet, iter: 0 i:37, pairs changed 4\n",
      "fullSet, iter: 0 i:38, pairs changed 4\n",
      "fullSet, iter: 0 i:39, pairs changed 4\n",
      "fullSet, iter: 0 i:40, pairs changed 4\n",
      "fullSet, iter: 0 i:41, pairs changed 4\n",
      "fullSet, iter: 0 i:42, pairs changed 4\n",
      "fullSet, iter: 0 i:43, pairs changed 4\n",
      "fullSet, iter: 0 i:44, pairs changed 4\n",
      "fullSet, iter: 0 i:45, pairs changed 4\n",
      "fullSet, iter: 0 i:46, pairs changed 5\n",
      "fullSet, iter: 0 i:47, pairs changed 5\n",
      "fullSet, iter: 0 i:48, pairs changed 5\n",
      "fullSet, iter: 0 i:49, pairs changed 5\n",
      "fullSet, iter: 0 i:50, pairs changed 5\n",
      "fullSet, iter: 0 i:51, pairs changed 5\n",
      "L==H\n",
      "fullSet, iter: 0 i:52, pairs changed 5\n",
      "fullSet, iter: 0 i:53, pairs changed 5\n",
      "L==H\n",
      "fullSet, iter: 0 i:54, pairs changed 5\n",
      "L==H\n",
      "fullSet, iter: 0 i:55, pairs changed 5\n",
      "fullSet, iter: 0 i:56, pairs changed 5\n",
      "fullSet, iter: 0 i:57, pairs changed 5\n",
      "fullSet, iter: 0 i:58, pairs changed 5\n",
      "fullSet, iter: 0 i:59, pairs changed 5\n",
      "fullSet, iter: 0 i:60, pairs changed 5\n",
      "fullSet, iter: 0 i:61, pairs changed 5\n",
      "fullSet, iter: 0 i:62, pairs changed 5\n",
      "fullSet, iter: 0 i:63, pairs changed 5\n",
      "fullSet, iter: 0 i:64, pairs changed 5\n",
      "fullSet, iter: 0 i:65, pairs changed 5\n",
      "fullSet, iter: 0 i:66, pairs changed 5\n",
      "fullSet, iter: 0 i:67, pairs changed 5\n",
      "fullSet, iter: 0 i:68, pairs changed 5\n",
      "L==H\n",
      "fullSet, iter: 0 i:69, pairs changed 5\n",
      "fullSet, iter: 0 i:70, pairs changed 5\n",
      "fullSet, iter: 0 i:71, pairs changed 5\n",
      "fullSet, iter: 0 i:72, pairs changed 5\n",
      "fullSet, iter: 0 i:73, pairs changed 5\n",
      "fullSet, iter: 0 i:74, pairs changed 5\n",
      "fullSet, iter: 0 i:75, pairs changed 5\n",
      "fullSet, iter: 0 i:76, pairs changed 5\n",
      "fullSet, iter: 0 i:77, pairs changed 5\n",
      "fullSet, iter: 0 i:78, pairs changed 5\n",
      "fullSet, iter: 0 i:79, pairs changed 5\n",
      "fullSet, iter: 0 i:80, pairs changed 5\n",
      "fullSet, iter: 0 i:81, pairs changed 5\n",
      "fullSet, iter: 0 i:82, pairs changed 5\n",
      "fullSet, iter: 0 i:83, pairs changed 5\n",
      "fullSet, iter: 0 i:84, pairs changed 5\n",
      "fullSet, iter: 0 i:85, pairs changed 5\n",
      "fullSet, iter: 0 i:86, pairs changed 5\n",
      "fullSet, iter: 0 i:87, pairs changed 5\n",
      "fullSet, iter: 0 i:88, pairs changed 5\n",
      "fullSet, iter: 0 i:89, pairs changed 5\n",
      "fullSet, iter: 0 i:90, pairs changed 5\n",
      "fullSet, iter: 0 i:91, pairs changed 5\n",
      "fullSet, iter: 0 i:92, pairs changed 5\n",
      "fullSet, iter: 0 i:93, pairs changed 5\n",
      "fullSet, iter: 0 i:94, pairs changed 6\n",
      "fullSet, iter: 0 i:95, pairs changed 6\n",
      "fullSet, iter: 0 i:96, pairs changed 6\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:97, pairs changed 6\n",
      "fullSet, iter: 0 i:98, pairs changed 6\n",
      "fullSet, iter: 0 i:99, pairs changed 6\n",
      "iteration number: 1\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:0, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:3, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:4, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:17, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:18, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:25, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:46, pairs changed 0\n",
      "non-bound, iter: 1 i:55, pairs changed 0\n",
      "non-bound, iter: 1 i:94, pairs changed 0\n",
      "iteration number: 2\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:0, pairs changed 0\n",
      "fullSet, iter: 2 i:1, pairs changed 0\n",
      "fullSet, iter: 2 i:2, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:3, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:4, pairs changed 0\n",
      "fullSet, iter: 2 i:5, pairs changed 0\n",
      "fullSet, iter: 2 i:6, pairs changed 0\n",
      "fullSet, iter: 2 i:7, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:8, pairs changed 0\n",
      "fullSet, iter: 2 i:9, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:10, pairs changed 0\n",
      "fullSet, iter: 2 i:11, pairs changed 0\n",
      "fullSet, iter: 2 i:12, pairs changed 0\n",
      "fullSet, iter: 2 i:13, pairs changed 0\n",
      "fullSet, iter: 2 i:14, pairs changed 0\n",
      "fullSet, iter: 2 i:15, pairs changed 0\n",
      "fullSet, iter: 2 i:16, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:17, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:18, pairs changed 0\n",
      "fullSet, iter: 2 i:19, pairs changed 0\n",
      "fullSet, iter: 2 i:20, pairs changed 0\n",
      "fullSet, iter: 2 i:21, pairs changed 0\n",
      "fullSet, iter: 2 i:22, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:23, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:24, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:25, pairs changed 0\n",
      "fullSet, iter: 2 i:26, pairs changed 0\n",
      "fullSet, iter: 2 i:27, pairs changed 0\n",
      "fullSet, iter: 2 i:28, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:29, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:30, pairs changed 0\n",
      "fullSet, iter: 2 i:31, pairs changed 0\n",
      "fullSet, iter: 2 i:32, pairs changed 0\n",
      "fullSet, iter: 2 i:33, pairs changed 0\n",
      "fullSet, iter: 2 i:34, pairs changed 0\n",
      "fullSet, iter: 2 i:35, pairs changed 0\n",
      "fullSet, iter: 2 i:36, pairs changed 0\n",
      "fullSet, iter: 2 i:37, pairs changed 0\n",
      "fullSet, iter: 2 i:38, pairs changed 0\n",
      "fullSet, iter: 2 i:39, pairs changed 0\n",
      "fullSet, iter: 2 i:40, pairs changed 0\n",
      "fullSet, iter: 2 i:41, pairs changed 0\n",
      "fullSet, iter: 2 i:42, pairs changed 0\n",
      "fullSet, iter: 2 i:43, pairs changed 0\n",
      "fullSet, iter: 2 i:44, pairs changed 0\n",
      "fullSet, iter: 2 i:45, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:46, pairs changed 0\n",
      "fullSet, iter: 2 i:47, pairs changed 0\n",
      "fullSet, iter: 2 i:48, pairs changed 0\n",
      "fullSet, iter: 2 i:49, pairs changed 0\n",
      "fullSet, iter: 2 i:50, pairs changed 0\n",
      "fullSet, iter: 2 i:51, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:52, pairs changed 0\n",
      "fullSet, iter: 2 i:53, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:54, pairs changed 0\n",
      "fullSet, iter: 2 i:55, pairs changed 0\n",
      "fullSet, iter: 2 i:56, pairs changed 0\n",
      "fullSet, iter: 2 i:57, pairs changed 0\n",
      "fullSet, iter: 2 i:58, pairs changed 0\n",
      "fullSet, iter: 2 i:59, pairs changed 0\n",
      "fullSet, iter: 2 i:60, pairs changed 0\n",
      "fullSet, iter: 2 i:61, pairs changed 0\n",
      "fullSet, iter: 2 i:62, pairs changed 0\n",
      "fullSet, iter: 2 i:63, pairs changed 0\n",
      "fullSet, iter: 2 i:64, pairs changed 0\n",
      "fullSet, iter: 2 i:65, pairs changed 0\n",
      "fullSet, iter: 2 i:66, pairs changed 0\n",
      "fullSet, iter: 2 i:67, pairs changed 0\n",
      "fullSet, iter: 2 i:68, pairs changed 0\n",
      "fullSet, iter: 2 i:69, pairs changed 0\n",
      "fullSet, iter: 2 i:70, pairs changed 0\n",
      "fullSet, iter: 2 i:71, pairs changed 0\n",
      "fullSet, iter: 2 i:72, pairs changed 0\n",
      "fullSet, iter: 2 i:73, pairs changed 0\n",
      "fullSet, iter: 2 i:74, pairs changed 0\n",
      "fullSet, iter: 2 i:75, pairs changed 0\n",
      "fullSet, iter: 2 i:76, pairs changed 0\n",
      "fullSet, iter: 2 i:77, pairs changed 0\n",
      "fullSet, iter: 2 i:78, pairs changed 0\n",
      "fullSet, iter: 2 i:79, pairs changed 0\n",
      "fullSet, iter: 2 i:80, pairs changed 0\n",
      "fullSet, iter: 2 i:81, pairs changed 0\n",
      "fullSet, iter: 2 i:82, pairs changed 0\n",
      "fullSet, iter: 2 i:83, pairs changed 0\n",
      "fullSet, iter: 2 i:84, pairs changed 0\n",
      "fullSet, iter: 2 i:85, pairs changed 0\n",
      "fullSet, iter: 2 i:86, pairs changed 0\n",
      "fullSet, iter: 2 i:87, pairs changed 0\n",
      "fullSet, iter: 2 i:88, pairs changed 0\n",
      "fullSet, iter: 2 i:89, pairs changed 0\n",
      "fullSet, iter: 2 i:90, pairs changed 0\n",
      "fullSet, iter: 2 i:91, pairs changed 0\n",
      "fullSet, iter: 2 i:92, pairs changed 0\n",
      "fullSet, iter: 2 i:93, pairs changed 0\n",
      "fullSet, iter: 2 i:94, pairs changed 0\n",
      "fullSet, iter: 2 i:95, pairs changed 0\n",
      "fullSet, iter: 2 i:96, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:97, pairs changed 0\n",
      "fullSet, iter: 2 i:98, pairs changed 0\n",
      "fullSet, iter: 2 i:99, pairs changed 0\n",
      "iteration number: 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b= [[-2.89901748]]\n",
      "alphas[alphas>0]= [[ 0.06961952  0.0169055   0.0169055   0.0272699   0.04522972  0.0272699\n",
      "   0.0243898   0.06140181  0.06140181]]\n",
      "shape(alphas[alphas > 0])= (1L, 9L)\n",
      "[3.542485, 1.977398] -1.0\n",
      "[2.114999, -0.004466] -1.0\n",
      "[8.127113, 1.274372] 1.0\n",
      "[4.658191, 3.507396] -1.0\n",
      "[8.197181, 1.545132] 1.0\n",
      "[7.40786, -0.121961] 1.0\n",
      "[6.960661, -0.245353] 1.0\n",
      "[6.080573, 0.418886] 1.0\n",
      "[3.107511, 0.758367] -1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMJD/D/V6nlb7xu3GAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x84da8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 获取特征和目标变量\n",
    "    dataArr, labelArr = loadDataSet('6.SVM/testSet.txt')\n",
    "    # print labelArr\n",
    "\n",
    "    # b是常量值， alphas是拉格朗日乘子\n",
    "    b, alphas = smoP(dataArr, labelArr, 0.6, 0.001, 40)\n",
    "    print '\\n\\n\\n'\n",
    "    print 'b=', b\n",
    "    print 'alphas[alphas>0]=', alphas[alphas > 0]\n",
    "    print 'shape(alphas[alphas > 0])=', shape(alphas[alphas > 0])\n",
    "    for i in range(100):\n",
    "        if alphas[i] > 0:\n",
    "            print dataArr[i], labelArr[i]\n",
    "    # 画图\n",
    "    ws = calcWs(alphas, dataArr, labelArr)\n",
    "    plotfig_SVM(dataArr, labelArr, ws, b, alphas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
